\section{Модифицированный байесовский классификатор}\label{sec:ch1/modified_bayesian_classifier}

\subsection{Задача классификации и байесовский классификатор}\label{subsec:ch1/classification_task}

Одной из задач, решаемых с помощью методов машинного обучения с учителем, является классификация~\cite{vorontsov2008lections}. Пусть \(D = (X, Y)\) -- случайный вектор с некоторым распределением \(P\), причём \(X \in [0, 1]^d\) и \(Y \in \{\pm 1\}\). Обозначим отвечающее \(P\) распределение \(X\) через \(P_X\) . В дальнейшем будем называть значения \(X\) признаками, \(Y\) -- метками классов, а \(d\) -- размерностью признакового пространства. Задача бинарной классификации заключается в построении дискриминантной функции \(f\): \([0, 1]^d \rightarrow \{\pm 1\}\), которая значениям признаков ставит в соответствие метки классов.

Общую задачу классификации можно записать в следующем виде:

\begin{equation}
    \label{eq:binary_classification}
    \mathbb{P}(Y \neq f(X)) \rightarrow \min\limits_{f},
\end{equation}
где минимум берется по всем функциям со значениями \(\pm 1\). Аналогично, в этих терминах задача регрессии принимает вид

\begin{equation}
    \label{eq:binary_regression}
    \mathbb{E}\left(Y - f(X)\right)^2 \rightarrow \min\limits_{f},
\end{equation}
где \(\mathbb{E}\) – отвечающее \(P\) математическое ожидание, а минимум берётся по всем функциям на \([0, 1]^d\).

Решение задачи регрессии – это условное математическое ожидание
\[
    g(x) = \mathbb{E}\left(Y|X=x\right) = 2\mathbb{P}(Y=1|X=x) - 1, x \in [0, 1]^d,
\]

как следует из элементарного соотношения

\[
    \mathbb{E}\left(Y-f(X)\right)^2 = \mathbb{E}\left(Y-g(X)\right)^2 + \mathbb{E}\left(g(X)-f(X)\right)^2.
\]

Вообще говоря, \(g(x)\) определено однозначно на \([0, 1]^d\) только \(P_X\)-почти наверное. В частности, вне \(\mathbb{S}\) – носителя распределения вектора \(X\) в \([0, 1]^d\) – функция условного математического ожидания \(g(x)\) может принимать какие угодно значения.

Решение задачи классификации – это байесовский классификатор~\cite{vorontsov2008bayes}

\nomenclature{\(s(x)\)}{байесовский классификатор}

\begin{equation}
    \label{eq:bayesian_classifier}
    s(x) = \left\{
\begin{alignedat}{2}
    &&1, \quad &\text{eсли } g(x) > 0 \text{ и } x \in \mathbb{S}, \\
    &\text{любое из значений } &\pm 1, \quad & \text{eсли } g(x) = 0 \text{ или } x \notin \mathbb{S}, \\
    &&-1, \quad &\text{eсли } g(x) < 0 \text{ и } x \in \mathbb{S}, \\
\end{alignedat}
\right.
\end{equation}
отвечающий \(g\) (данной версии условного математического ожидания). Последнее следует из того, что для \(f\) со значениями \(\pm 1\) всегда выполнены равенства

\[
    4\mathbb{P}(Y \neq f(X)) = \mathbb{E}\left(Y - f(X)\right)^2 = \mathbb{E}\left(Y - g(X)\right)^2 + \mathbb{E}\left(g(X) - f(X)\right)^2
\]

Согласно \cref{eq:bayesian_classifier}, зоной неопределённости байесовского классификатора, отвечающего \(g\), является множество \([0,1]^d \setminus \mathbb{S} \cup \{x: g(x) = 0\}\).

На практике распределение \(P\) неизвестно, но при этом, как правило, имеется выборка из \(P\), так что для оценки байесовского классификатора используются эмпирические аналоги \cref{eq:binary_classification} и \cref{eq:binary_regression} с регуляризацией~\cite{obi2023review} и различными ограничениями на классы функций \(f\), по которым ведётся оптимизация.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Проблематика}\label{subsec:ch1/problems}

Ключевая трудность, с которой сталкиваются методы машинного обучения~\cite{muhamedyev2015machine}, заключается в том, что как этап обучения, так и последующие выводы обоснованы лишь в пределах носителя распределения имеющихся данных. Как было отмечено ранее, область вне носителя \(\mathbb{S}\) распределения случайного вектора \(X\) представляет собой зону неопределённости для байесовского классификатора. Однако распространённые алгоритмы машинного обучения, как правило, не осуществляют явную оценку границ множества \(\mathbb{S}\), формируя при этом конкретные правила классификации на всём компакте \([0, 1]^d\), включая точки, лежащие вне \(\mathbb{S}\). При наличии сдвигов или искажений в распределении данных (как в обучающей, так и тестовой выборках) такие выводы за пределами \(\mathbb{S}\) могут оказаться некорректными. В этих случаях естественным решением является отказ от классификации, однако большинство современных методов не обладают встроенными механизмами для автоматического отказа от принятия решения, что снижает их надёжность в прикладных задачах.

\nomenclature{\(\mathbb{S}\)}{носитель распределения}

Рассмотрим подробнее ситуации, в которых отказ от принятия решения является обоснованным.

\begin{enumerate}
    \item \textbf{Выброс.} Если наблюдение существенно отличается от всех прочих, то модель не располагает достаточной информацией для корректной классификации. Обычно для обнаружения таких объектов применяются специальные процедуры предварительной обработки, ориентированные на выявление выбросов~\cite{boukerche2020outlier}. Однако эти методы, как правило, требуют задания гиперпараметров~\cite{ding2022hyperparameter} и применяются перед обучением модели, что не позволяет гибко учитывать особенности распределения обучающих и тестовых данных.

    \item \textbf{Выход за распределение (OOD, out-of-distribution).} При изменении распределения входных данных модель может оказаться неспособной дать обоснованное решение~\cite{yang2024generalized}. Существующие подходы к детекции подобных случаев делятся на три класса: статистические методы~\cite{caron2024view}, моделирование сдвигов~\cite{vijendran2025boost} и применение вспомогательных моделей машинного обучения~\cite{shmuel2025machine}. Статистические методы отличаются высокой чувствительностью к выбору конкретного подхода и параметров. Моделирование сдвигов требует априорных предположений о характере изменений распределения и его динамике во времени, что затрудняет автоматизацию. Методы на основе машинного обучения сами подвержены проблеме выхода за распределение, но уже применительно к детектору.
    
    \item \textbf{Зона пересечения классов.} Если носители распределений нескольких классов пересекаются, то для новых наблюдений, попавших в такую область, вероятности принадлежности к разным классам могут быть примерно равны. В этом случае разумно отказаться от автоматической классификации и передать наблюдение на рассмотрение эксперту, обладающему дополнительной информацией.
\end{enumerate}

Таким образом, отказ от классификации представляется оправданным в зоне неопределённости, а именно для наблюдений, принадлежащих множеству \([0, 1]^d \setminus \mathbb{S} \cup \{x: g(x) = 0\}\). Главная трудность заключается в том, что множество \(\mathbb{S}\) априорно неизвестно. В следующем разделе рассматривается подход, позволяющий обойтись без явной оценки носителя \(\mathbb{S}\).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Модификация байесовского классификатора}\label{subsec:ch1/bayesian_classifier_modification}

Одним из возможных подходов к преодолению указанной проблемы является модификация байесовского классификатора путём экстраполяции его поведения за пределы носителя \(\mathbb{S}\). Такая экстраполяция достигается за счёт добавления к обучающей выборке искусственных наблюдений, компоненты которых равномерно распределены на всём компакте \([0, 1]^d\), а метки классов фиксированы и равны нулю~\cite{lukyanov2024extrapolation}.

В результате этой модификации исходное распределение случайного вектора \((X, Y)\), принимающего значения в пространстве \([0, 1]^d \times \{\pm 1\}\), заменяется на новое распределение на \([0, 1]^d \times \{-1, 0, +1\}\), представляющее собой смесь двух распределений:

\[
    P_\alpha = (1 - \alpha) P + \alpha \hat{P},
\]

где \(\alpha \in (0, 1)\), \(P\) -- исходное распределение обучающих данных, \(\hat{P}\) -- распределение, при котором вектор признаков равномерно распределён на \([0, 1]^d\), а метка класса тождественно равна нулю.

Соответствующее маргинальное распределение признаков \(X\) при этом принимает следующий вид:

\[
    \lambda_\alpha = (1 - \alpha) P_X + \alpha \lambda,
\]

где \(\lambda\) -- мера Лебега на \([0, 1]^d\), а \(P_X\) -- распределение признаков \(X\), когда вектор \((X, Y)\) распределён согласно \(P\). Обозначим через \(\mathbb{E}_\alpha\) математическое ожидание относительно распределения \(P_\alpha\), а через \(\mathbb{S}\) -- носитель распределения \(P_X\).

В силу разложения Лебега и теоремы Радона–Никодима всегда найдутся неотрицательная интегрируемая функция \(\rho\) на \([0, 1]^d\) и борелевское множество \(A \subseteq \mathbb{S}\) нулевой лебеговой меры такие, что

\[
    P_X(B) = \int_B \rho(x) dx + P_X(A \cap B)
\]

для всех борелевских множеств \(B\) в \([0, 1]^d\).

\begin{theorem}
\label{theorem:modified_bayesian}
    Для всякого \(\alpha \in (0, 1)\) решение \(g_\alpha\) задачи регрессии

    \begin{equation}
        \label{eq:regression_alpha}
        \mathbb{E}_\alpha \left(Y - f(X)\right)^2 \rightarrow \min\limits_{f}
    \end{equation}
    
    \noindent существует, это решение единственно \(P_X\)- и \(\lambda\)-п. н. и может быть задано
формулой

    \begin{equation}
        \label{eq:classfier_alpha}
        g_\alpha(x) = \left\{
    \begin{alignedat}{2}
        &&g(x), \quad &\text{если } x \in A, \\
        &&\frac{(1-\alpha) g(x) \rho(x)}{\alpha + (1 - \alpha) \rho(x)}, \quad & \text{если } \rho(x) > 0 \text{ и } x \in \mathbb{S} \setminus A, \\
        &&0, \quad &\text{если или } \rho(x) = 0 \text{ и } x \in \mathbb{S} \setminus A, \text{или } x \notin \mathbb{S}, \\
    \end{alignedat}
    \right.
    \end{equation}
    
    \noindent здесь минимум берется по всем (борелевским) функциям \(f\) и
    \[g(x)=\mathbb{E}\left(Y|X=x\right) \text{ на } [0, 1]^d.\]
    
    \noindent При этом классификатор \(s_\alpha = s_\alpha(x)\), \(x \in [0, 1]^d\), заданный формулой \cref{eq:bayesian_classifier} c заменой \(g\) на любое решение \(g_\alpha\) задачи \cref{eq:regression_alpha} и \(\mathbb{S}\) на \([0, 1]^d\), обладает следующими свойствами:

    \begin{itemize}
        \item \(s_\alpha\) реализует минимум в задаче классификации
              \[\mathbb{P}(Y \neq f(X)) \rightarrow \min\limits_{f},\]
              \noindent где минимум берется по всем (борелевским) функциям со значениями \(\pm 1\);

        \item зоной неопределённости \(s_\alpha\) является множество \(\{x \in [0, 1]^d: g_\alpha(x) = 0\}\), которое покрывает \(\lambda\)-п.н. множество \([0, 1]^d \setminus \mathbb{S}\), где \(\mathbb{S}\) -- носитель распределения \(P_X\).
    \end{itemize}
\end{theorem}

\nomenclature{\(s_\alpha(x)\)}{модифицированный байесовский классификатор}

Доказательство \cref{theorem:modified_bayesian} приведено в приложении~\cref{app:B1}.

Пусть вместо \cref{eq:regression_alpha} рассматривается задача вида

\begin{equation}
    \label{eq:regression_alpha_penalize}
    \mathbb{E}_\alpha \left(Y - f(X)\right)^2 + Pen(f) \rightarrow \min\limits_{f \in \mathcal{F}},
\end{equation}

\noindent где \(\mathcal{F}\) -- некоторое параметрическое семейство функций (к примеру, нейросетей заданной архитектуры), а \(Pen(f)\) -- регуляризационное слагаемое-штраф.

Тогда, как следует из доказательства~\cref{theorem:modified_bayesian}, в терминах минимизирующих функций задача \cref{eq:regression_alpha_penalize} будет эквивалентна задаче приближения \(g_\alpha\) -- любого решения задачи \cref{eq:regression_alpha} -- функцией из класса \(\mathcal{F}\) с учётом штрафа \(Pen(f)\):

\begin{equation}
    \label{eq:approximation_penalize}
    (1 - \alpha)\|g_\alpha - f\|^2_{P_X} + \alpha \|g_\alpha - f\|^2_\lambda + Pen(f) \rightarrow \min\limits_{f \in \mathcal{F}},
\end{equation}

\noindent где \(\| \cdot \|_\mu\) -- это \(L_2\)-норма относительно меры \(P_X\) или \(\lambda\).

Как было отмечено ранее (см. раздел \cref{subsec:ch1/classification_task}), в практических задачах распределение \(P\) априорно неизвестно, а классификационное правило строится по конечной выборке, представляющей реализацию этого распределения. В таких условиях задача классификации заменяется на эмпирический аналог задачи~\cref{eq:regression_alpha_penalize}, решаемый с использованием методов машинного обучения.

Поскольку в эмпирической постановке оценка функции принятия решения подвержена статистическим флуктуациям, область отказа от классификации следует расширить, чтобы учесть возможную неопределённость вблизи границы между классами. Для этого вводится дополнительный гиперпараметр \(\beta > 0\), регулирующий ширину зоны неопределённости~\cite{mitsobi2023,mitsobi2024}. Отказ от принятия решения осуществляется для тех наблюдений, по которым оценка эмпирической функции \(f\), соответствующей приближённому решению задачи~\cref{eq:regression_alpha_penalize}, по модулю не превосходит \(\beta\): \(|f(x)| \leq \beta\).

\nomenclature{\(\beta\)}{порог доверия, гиперпараметр}

Такое уточнение позволяет повысить надёжность классификатора за счёт уменьшения числа потенциально ошибочных решений в областях, где уверенность модели недостаточна.

Параметр \(\beta\) имеет ясную интерпретацию: он определяет минимальный уровень уверенности классификатора, при котором принимается решение. В предельном случае \(\beta = 0\) отказ от классификации осуществляется только тогда, когда значение \(f(x)\) точно равно нулю, что соответствует ситуации, в которой размер обучающей выборки стремится к бесконечности, то есть распределение \(P\) считается полностью известным.
