\section{Связь нейросетевой и гистограммной аппроксимаций. Асимптотические свойства гистограммной аппроксимации}\label{sec:ch1/hist_neural_approximations}

Гистограммная аппроксимация, как было показано выше, представляет собой естественный способ приближённой оценки апостериорной вероятности класса по обучающим данным. В каждой ячейке пространства признаков, определённой системой линейных неравенств, оценивается эмпирическое распределение классов на основе количества объектов, попавших в соответствующую область. В частности, выход функции гистограммной аппроксимации можно записать как

\[
h_n^*(X) = \frac{n_{+1}(X) - n_{-1}(X)}{n_{-1}(X) + n_0(X) + n_{+1}(X)},
\]

где \(n_{-1}(X)\) и \(n_{+1}(x)\) -- количество объектов классов \(-1\) и \(+1\) соответственно, а \(n_0\) -- количество фоновых точек в ячейке, содержащей наблюдение \(X\).

Таким образом, \(h_n^*(X)\) соответствует разности логарифмов аппроксимированных правдоподобий классов и служит приближением разности апостериорных вероятностей.

Предполагая, что плотности распределения классов равномерно непрерывны, можно показать, что гистограмма является строго состоятельной оценкой этих плотностей. Результаты работы~\cite{devroye2013probabilistic} позволяют утверждать, что при росте объёма обучающей выборки \(n \to \infty\) и одновременном увеличении числа ячеек (или, эквивалентно числа нейронов \(kL \to \infty\), отвечающего за глубину разбиения пространства) имеет место следующее соотношение:

\begin{equation}
    \label{eq:binary_consistency}
    \mathbb{E}\left( h_n^*(X) - c_n^*(X) \right)^2 \to 0, \quad n \to \infty,    
\end{equation}

где \(c_n^*(x)\) -- выход модифицированного персептрона, аппроксимирующего байесовскую границу принятия решения.

Этот результат обосновывает возможность замены гистограммной аппроксимации на нейросетевую, сохраняющую асимптотические свойства при существенно меньших требованиях к вычислительным ресурсам. В отличие от гистограммы, для работы персептрона не требуется хранение всей обучающей выборки или экспоненциально большого числа ячеек.

Следствием приведённого утверждения является практический критерий принятия решения на основе выхода персептрона. Поскольку \(c_n^*(x)\) приближает \(h_n^*(x)\), то в условиях асимптотической сходимости разумно вводить порог отказа \(\beta\) и принимать решение о принадлежности к одному из классов только при условии

\[
|c_n^*(x)| > \beta.
\]

Тем самым достигается контроль над уверенностью классификатора: чем ближе значение \(c_n^*(x)\) к нулю, тем ниже надёжность предсказания. Предложенная схема позволяет реализовать отказ от ответа в ситуациях, когда классификатор не обладает достаточной апостериорной уверенностью, и одновременно существенно снижает вычислительную сложность по сравнению с прямой реализацией гистограммной аппроксимации.
